<!doctype html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>Sharath Chandra Raparthy — Research Engineer, Google DeepMind</title>
    <meta name="author" content="Sharath Chandra Raparthy" />
    <meta name="description"
      content="Sharath Chandra Raparthy — Research Engineer at Google DeepMind working on open-endedness. Previously at FAIR (Meta), Reka AI, and Mila. Core contributor to Llama 3." />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" type="text/css" href="stylesheet.css" />
    <link rel="icon" type="image/png" href="images/icon.png" />
  </head>

  <body>
    <div class="site-container">
    
      <!-- ==================== HERO / INTRO ==================== -->
      <section class="hero-section">
        <div class="hero-text">
          <h1 class="hero-name">Sharath Chandra Raparthy</h1>
    
          <p>
            I am a Research Engineer at
            <a href="https://deepmind.google/">Google DeepMind</a>, working in
            the Open-Endedness team.
            </p>

          <p>
            Previously, I was a Member of Technical Staff at
            <a href="https://www.reka.ai/">Reka AI</a>, building general-purpose
            multimodal agents. Before that, I was an AI Resident at
            <a href="https://ai.meta.com/">FAIR (Meta)</a>, where I was a core
            contributor to
            <a href="https://arxiv.org/abs/2407.21783">Llama 3</a> — shipping
            tool-use and mathematical reasoning capabilities — and co-led
            <a href="https://arxiv.org/abs/2402.16822">Rainbow Teaming</a>,
            a method for stress-testing and improving LLM robustness at scale.
            My research spans LLM reasoning, open-ended learning, and
            in-context reinforcement learning.
            </p>

          <p>
            I hold a Master's (with thesis) from
            <a href="https://mila.quebec/en/">Mila</a>, advised by
            <a href="https://sites.google.com/site/irinarish/">Irina Rish</a>,
            and spent time at
            <a href="https://www.recursion.com">Recursion</a> applying
            GFlowNets to drug discovery.
            </p>

          <p>
            When not training models, you'll find me running long distances,
            cooking, reading, or out with a camera.
            </p>

          <!-- Social Links -->
          <div class="social-links">
            <a class="social-link" href="mailto:sharathraparthy@gmail.com">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path
                  d="M20 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4l-8 5-8-5V6l8 5 8-5v2z" />
              </svg>
              Email
            </a>
            <a class="social-link" href="https://github.com/SharathRaparthy" target="_blank">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path
                  d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z" />
              </svg>
              GitHub
            </a>
            <a class="social-link" href="https://scholar.google.ca/citations?user=S1R0_UMAAAAJ&hl=en" target="_blank">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path
                  d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 100 14 7 7 0 000-14z" />
              </svg>
              Google Scholar
            </a>
          </div>
          </div>

        <div class="hero-photo">
          <img src="images/sharath_sf.jpg" alt="Sharath Chandra Raparthy" />
        </div>
        </section>

      <!-- ==================== NEWS ==================== -->
      <section class="news-section">
        <h2>News</h2>
        <div class="news-fade">
          <div class="news-container">
            <ul class="news-list">
              <li class="news-item">
                <span class="news-date">Nov 2025:</span>
                Joined <a href="https://deepmind.google/">Google DeepMind</a> as a Research Engineer in the open-endedness
                team.
              </li>
          <li class="news-item">
            <span class="news-date">Oct 2024:</span>
            Joined <a href="https://www.reka.ai/">Reka AI</a> as a Member of Technical Staff.
          </li>
          <li class="news-item">
            <span class="news-date">Sep 2024:</span>
            <a href="https://arxiv.org/abs/2402.16822">Rainbow Teaming</a> got accepted into <a href="https://neurips.cc">NeurIPS
              2024</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Jul 2024:</span>
            Excited to share that I'm a core contributor to
            <a href="https://arxiv.org/abs/2407.21783">The Llama 3 Herd of Models</a> paper, now available on arXiv.
          </li>
          <li class="news-item">
            <span class="news-date">Jun 2024:</span>
            <a href="https://arxiv.org/abs/2403.04642">GLoRe</a> and
            <a href="https://arxiv.org/abs/2312.03801">In-context RL</a> papers got accepted to
            <a href="https://icml.cc">ICML 2024</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Apr 2024:</span>
            Super happy to release <a href="https://ai.meta.com/blog/meta-llama-3/">Llama-3 preview models</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Mar 2024:</span>
            New preprint on <a href="https://arxiv.org/abs/2402.16822">Rainbow Teaming: Open-Ended Generation of Diverse
              Adversarial Prompts</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Mar 2024:</span>
            New preprint on <a href="https://arxiv.org/abs/2403.04642">GLoRe: When, Where, and How to Improve LLM Reasoning via
              Global and Local Refinements</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Mar 2024:</span>
            New preprint on <a href="https://arxiv.org/abs/2312.03801">Teaching Large Language Models to Reason with Reinforcement
              Learning</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Feb 2024:</span>
            Featured on <a href="https://www.talkrl.com/episodes/sharath-chandra-raparthy">TalkRL podcast</a> to discuss our work
            on In-context Learning for Sequential Decision Making.
          </li>
          <li class="news-item">
            <span class="news-date">Dec 2023:</span>
            New preprint on <a href="https://arxiv.org/abs/2312.03801">Generalization to New Sequential Decision Making Tasks with
              In-Context Learning</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Oct 2022:</span>
            Our work <a href="https://arxiv.org/abs/2210.12765">Multi-Objective GFlowNets</a> got accepted at ICML 2023.
          </li>
          <li class="news-item">
            <span class="news-date">Aug 2022:</span>
            Our work <a href="https://arxiv.org/abs/2110.09419">Continual Learning In Environments With Polynomial Mixing
              Times</a> got accepted at NeurIPS 2022.
          </li>
          <li class="news-item">
            <span class="news-date">Aug 2022:</span>
            Co-organizing <a href="https://paperswithcode.com/rc2022">Machine Learning Reproducibility Challenge — 2022</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Aug 2022:</span>
            Joining <a href="https://ai.facebook.com/">MetaAI</a> as an AI Resident.
          </li>
          <li class="news-item">
            <span class="news-date">Apr 2022:</span>
            Joining <a href="https://www.recursion.com/">Recursion</a> as a research intern.
          </li>
          <li class="news-item">
            <span class="news-date">Oct 2021:</span>
            Co-organizing <a href="https://paperswithcode.com/rc2021">Machine Learning Reproducibility Challenge — 2021</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Oct 2021:</span>
            Our work on <a href="https://arxiv.org/abs/2110.09419">compositional attention</a> got accepted at ICLR 2022 as a
            <span class="paper-venue-spotlight">Spotlight</span>.
          </li>
          <li class="news-item">
            <span class="news-date">Oct 2021:</span>
            New preprint: <a href="https://arxiv.org/abs/2110.09419">Continual Learning In Environments With Polynomial Mixing
              Times</a>.
          </li>
          <li class="news-item">
            <span class="news-date">Sep 2020:</span>
            Started my masters at <a href="https://mila.quebec/">Mila</a>.
          </li>
          </ul>
        </div>
        </div>
        </section>
        
        <!-- ==================== RESEARCH ==================== -->
        <section class="research-section">
          <h2>Research</h2>
<!-- Llama 3.1 -->
<div class="paper-card">
  <div class="paper-image">
    <img src="images/llama3-1.png" alt="Llama 3.1" />
  </div>
  <div class="paper-content">
    <a href="https://ai.meta.com/blog/meta-llama-3/" class="paper-title">The Llama 3 Herd of Models</a>
    <div class="paper-authors">Llama Team</div>
    <div class="paper-links">
      <a class="paper-link" href="https://ai.meta.com/blog/meta-llama-3-1/">Blog</a>
      <a class="paper-link" href="https://arxiv.org/abs/2407.21783">Arxiv</a>
      <a class="paper-link" href="https://huggingface.co/collections/meta-llama/llama-31-669fc079a0c406a149a5738f">Model
        Card</a>
    </div>
    <p class="paper-description">
      We open-source Llama 3.1, a new family of foundation models with native support for multilinguality, coding,
      reasoning, and tool usage, featuring a 405B-parameter architecture with 128K context window. The models show
      comparable performance to GPT-4 across various tasks, and include Llama Guard 3 for safety.
    </p>
          </div>
          </div>
          
          <!-- Llama 3 Preview -->
          <div class="paper-card">
            <div class="paper-image">
              <img src="images/llama-3.png" alt="Llama 3" />
            </div>
            <div class="paper-content">
              <a href="https://ai.meta.com/blog/meta-llama-3/" class="paper-title">Llama-3 Preview Models</a>
              <div class="paper-authors">Llama Team</div>
              <div class="paper-links">
                <a class="paper-link" href="https://ai.meta.com/blog/meta-llama-3/">Blog</a>
              </div>
              <p class="paper-description">
                We introduce Llama 3 family of large language models (LLMs), a collection of pretrained and instruction tuned
                generative text models in 8 and 70B sizes. We achieve SOTA performance for LLM models at these scales.
              </p>
          </div>
          </div>
          
          <!-- Rainbow Teaming -->
          <div class="paper-card">
            <div class="paper-image">
              <img src="images/rainbow-teaming.png" alt="Rainbow Teaming" />
            </div>
            <div class="paper-content">
              <a href="https://arxiv.org/abs/2402.16822" class="paper-title">Rainbow Teaming: Open-Ended Generation of Diverse
                Adversarial Prompts</a>
              <div class="paper-authors">
                Mikayel Samvelyan*, <span class="me">Sharath Chandra Raparthy*</span>, Andrei Lupu*, Eric Hambro, Aram H.
                Markosyan, Manish Bhatt, Yuning Mao, Minqi Jiang, Jack Parker-Holder, Jakob Foerster, Tim Rocktäschel, Roberta
                Raileanu
              </div>
              <div class="paper-venue">Neural Information Processing Systems (NeurIPS), 2024</div>
              <div class="paper-links">
                <a class="paper-link" href="https://arxiv.org/abs/2402.16822">Paper</a>
                <a class="paper-link" href="https://sites.google.com/view/rainbow-teaming">Website</a>
                <a class="paper-link" href="https://twitter.com/_samvelyan/status/1762519344943104195">tl;dr</a>
              </div>
              <p class="paper-description">
                Introducing Rainbow Teaming, a new method for generating diverse adversarial prompts for LLMs via LLMs. It's a
                versatile tool for diagnosing model vulnerabilities across domains and creating data to enhance robustness &
                safety.
              </p>
          </div>
          </div>
          
          <!-- GLoRe -->
          <div class="paper-card">
            <div class="paper-image">
              <img src="images/galore.png" alt="GLoRe" />
            </div>
            <div class="paper-content">
              <a href="https://arxiv.org/abs/2402.10963" class="paper-title">GLoRe: When, Where, and How to Improve LLM Reasoning
                via Global and Local Refinements</a>
              <div class="paper-authors">
                Alex Havrilla, <span class="me">Sharath Chandra Raparthy</span>, Christoforus Nalmpantis, Jane Dwivedi-Yu, Maksym
                Zhuravinskyi, Eric Hambro, Roberta Raileanu
              </div>
              <div class="paper-venue">International Conference on Machine Learning (ICML), 2024</div>
              <div class="paper-links">
                <a class="paper-link" href="https://arxiv.org/abs/2402.10963">Paper</a>
                <a class="paper-link" href="https://twitter.com/Dahoas1/status/1760021603105288550">tl;dr</a>
              </div>
              <p class="paper-description">
                How to bootstrap the reasoning refinement capabilities of LLMs using synthetic data? We introduce GLoRe — applied
                on GSM8K, we can improve a strong RL finetuned Llama-2 13B by 12%.
              </p>
          </div>
          </div>
          
          <!-- Teaching LLMs to Reason -->
          <div class="paper-card">
            <div class="paper-image">
              <img src="images/gsm8k.png" alt="Teaching LLMs to Reason" />
            </div>
            <div class="paper-content">
              <a href="https://arxiv.org/abs/2403.04642" class="paper-title">Teaching Large Language Models to Reason with
                Reinforcement Learning</a>
              <div class="paper-authors">
                Alex Havrilla, Yuqing Du, <span class="me">Sharath Chandra Raparthy</span>, Christoforos Nalmpantis, Jane
                Dwivedi-Yu, Maksym Zhuravinskyi, Eric Hambro, Sainbayar Sukhbaatar, Roberta Raileanu
              </div>
              <div class="paper-venue">Arxiv</div>
              <div class="paper-links">
                <a class="paper-link" href="https://arxiv.org/abs/2403.04642">Paper</a>
                <a class="paper-link" href="https://twitter.com/Dahoas1/status/1766120506028359853">tl;dr</a>
              </div>
              <p class="paper-description">
                In this work, we set out to understand how different algorithms fare at improving LLM reasoning from feedback. We
                compare expert iteration, PPO, and return-conditioned RL using Llama-2 as the base model.
              </p>
          </div>
          </div>
          
          <!-- In-Context Learning SDM -->
          <div class="paper-card">
            <div class="paper-image">
              <img src="images/ICL-SDM.gif" alt="In-Context Learning for SDM" />
            </div>
            <div class="paper-content">
              <a href="https://arxiv.org/abs/2312.03801" class="paper-title">Generalization to New Sequential Decision Making
                Tasks with In-Context Learning</a>
              <div class="paper-authors">
                <span class="me">Sharath Chandra Raparthy</span>, Eric Hambro, Robert Kirk, Mikael Henaff, Roberta Raileanu
              </div>
              <div class="paper-venue">International Conference on Machine Learning (ICML), 2024</div>
              <div class="paper-links">
                <a class="paper-link" href="https://arxiv.org/abs/2312.03801">Paper</a>
                <a class="paper-link" href="">Code</a>
              </div>
              <p class="paper-description">
                Training autonomous agents to learn new tasks from few demonstrations is challenging, especially for sequential
                decision making which is sensitive to errors. We show that training transformers on diverse offline datasets of
                trajectories enables in-context learning of out-of-distribution sequential decision tasks from just a handful of
                demonstrations.
              </p>
          </div>
          </div>

        <!-- MOGFNs -->
        <div class="paper-card">
          <div class="paper-image">
            <img src="images/mogfn.png" alt="Multi-Objective GFlowNets" />
          </div>
          <div class="paper-content">
            <a href="https://arxiv.org/abs/2210.12765" class="paper-title">Multi-Objective GFlowNets</a>
            <div class="paper-authors">
              Moksh Jain, <span class="me">Sharath Chandra Raparthy</span>, Alex Hernandez-Garcia, Jarrid Rector-Brooks, Yoshua
              Bengio, Santiago Miret, Emmanuel Bengio
            </div>
            <div class="paper-venue">International Conference on Machine Learning (ICML), 2023</div>
            <div class="paper-links">
              <a class="paper-link" href="https://arxiv.org/abs/2210.12765">Paper</a>
              <a class="paper-link" href="https://github.com/sarthmit/Compositional-Attention">Code</a>
            </div>
            <p class="paper-description">
              We examine multi-objective optimization in applications like drug discovery and material design, noting the
              failure of existing methods to achieve diverse Pareto-optimal candidates. We introduce Multi-Objective GFlowNets
              (MOGFNs), featuring a novel Conditional GFlowNet that outperforms existing methods in Hypervolume, R2-distance,
              and candidate diversity.
            </p>
          </div>
          </div>

        <!-- Compositional Attention -->
        <div class="paper-card">
          <div class="paper-image">
            <img src="images/comp-atten.png" alt="Compositional Attention" />
          </div>
          <div class="paper-content">
            <a href="https://arxiv.org/abs/2110.09419v1" class="paper-title">Compositional Attention: Disentangling Search and
              Retrieval</a>
            <div class="paper-authors">
              Sarthak Mittal, <span class="me">Sharath Chandra Raparthy</span>, Irina Rish, Yoshua Bengio and Guillaume Lajoie
            </div>
            <div class="paper-venue">
              International Conference for Learning Representations (ICLR), 2022
              <span class="paper-venue-spotlight">Spotlight</span>
            </div>
            <div class="paper-links">
              <a class="paper-link" href="https://arxiv.org/abs/2110.09419v1">Paper</a>
              <a class="paper-link" href="https://github.com/sarthmit/Compositional-Attention">Code</a>
            </div>
            <p class="paper-description">
              We view the standard Multi-Head attention mechanism from the "Search-Retrieval" perspective and highlight the
              rigid associations of keys and values. We propose Compositional Attention, a drop-in replacement where
              redundancies are addressed by disentangling Searches and Retrievals and composing them dynamically in a
              context-dependent way.
            </p>
          </div>
        </div>

        <!-- Continual Learning -->
        <div class="paper-card">
          <div class="paper-image">
            <img src="images/figure-1-draft-11.png" alt="Continual Learning" />
          </div>
          <div class="paper-content">
            <a href="https://arxiv.org/abs/2112.07066" class="paper-title">Continual Learning In Environments With Polynomial
              Mixing Times</a>
            <div class="paper-authors">
              Matthew Riemer*, <span class="me">Sharath Chandra Raparthy*</span>, Ignacio Cases, Gopeshh Subbaraj, Maximilian
              Puelma Touzel and Irina Rish
            </div>
            <div class="paper-venue">Neural Information Processing Systems (NeurIPS), 2022</div>
            <div class="paper-links">
              <a class="paper-link" href="https://arxiv.org/abs/2112.07066">Paper</a>
              <a class="paper-link" href="https://github.com/sharathraparthy/polynomial-mixing-times">Code</a>
            </div>
            <p class="paper-description">
              We concentrate on "Mixing time" of a Markov chain induced by a policy as a major contributor to poor scaling. We
              categorize continual RL problems as Scalable MDPs, formally demonstrate that these exhibit polynomial mixing
              times, and propose three algorithms which clearly demonstrate sample efficiency.
            </p>
          </div>
          </div>
          
          <!-- Curriculum in Meta-RL -->
          <div class="paper-card">
            <div class="paper-image">
              <img src="images/meta-adr.png" alt="Curriculum in Meta-RL" />
            </div>
            <div class="paper-content">
              <a href="https://arxiv.org/abs/2002.07956" class="paper-title">Curriculum in Gradient-Based Meta-Reinforcement
                Learning</a>
              <div class="paper-authors">
                Bhairav Mehta, Tristan Deleu*, <span class="me">Sharath Chandra Raparthy*</span>, Christopher Pal, Liam Paull
              </div>
              <div class="paper-venue">ICLR BeTR-RL Workshop, 2021</div>
              <div class="paper-links">
                <a class="paper-link" href="https://arxiv.org/abs/2002.07956">Paper</a>
              </div>
              <p class="paper-description">
                In this work we study the under-studied parameter in meta learning, "Task Distributions". We show that MAML is
                sensitive to task distributions, and learning a curriculum of tasks instead of uniformly sampling helps the
                adaptation performance substantially.
              </p>
          </div>
          </div>

        <!-- CuNAS -->
        <div class="paper-card">
          <div class="paper-image">
            <img src="images/r:ss.png" alt="CuNAS" />
          </div>
          <div class="paper-content">
            <a href="https://arxiv.org/abs/2112.07066" class="paper-title">CuNAS — CUriosity-driven Neural-Augmented
              Simulator</a>
            <div class="paper-authors">
              <span class="me">Sharath Chandra Raparthy</span>, Melissa Mozifian, Liam Paull and Florian Golemo
            </div>
            <div class="paper-venue">RSS Sim2Real Workshop, 2021</div>
            <div class="paper-links">
              <a class="paper-link"
                href="https://docs.google.com/presentation/d/1nVbt0iQKFTOgHEQLLHbn1Wy3bMs_mWpyzfc0aZsN30U/edit?usp=sharing">Slides</a>
              <a class="paper-link"
                href="https://www.youtube.com/watch?v=Tlf5RG3OPF8&list=PL4BpvvbNDc3SxmswMbOljlUcCQJQ6eFDL&index=6">Talk</a>
            </div>
            <p class="paper-description">
              Transfer of policies from simulation to physical robots is an important open problem in deep RL. We propose a
              simple extension to Neural-Augmented Simulators based on artificial curiosity, leading to better exploration and
              consequently better sim-to-real transfer performance.
            </p>
          </div>
          </div>
          
          </section>
          
          <!-- ==================== FOOTER ==================== -->
          <footer class="site-footer">
            &copy; 2025 Sharath Chandra Raparthy
          </footer>
          
          </div>
          
          <!-- Scroll-reveal animation script -->
          <script>
            document.addEventListener('DOMContentLoaded', () => {
              // Add scroll-reveal class to paper cards, news section, and sections
              const targets = document.querySelectorAll(
                '.paper-card, .news-section, .research-section h2, .site-footer'
              );
              targets.forEach(el => el.classList.add('scroll-reveal'));

              // Observe and reveal
              const observer = new IntersectionObserver(
                (entries) => {
                  entries.forEach(entry => {
                    if (entry.isIntersecting) {
                      entry.target.classList.add('revealed');
                      observer.unobserve(entry.target);
                    }
                  });
                },
                { threshold: 0.1, rootMargin: '0px 0px -40px 0px' }
              );

              document.querySelectorAll('.scroll-reveal').forEach(el => observer.observe(el));
            });
          </script>
  </body>
</html>
