<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rose E. Wang</title>

  <meta name="author" content="Rose E. Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sharath Chandra Raparthy</name>
              </p>
              <p>I am an AI Resident at Meta AI where I work with Roberta Raileanu and Mikael Henaff. Prior to this, I was a Masters (with thesis) student at <a href="https://mila.quebec/en/">Mila</a> where I was supervised by  <a href="https://sites.google.com/site/irinarish/">Prof. Irina Rish.</a>
              I also spent some time at <a href="https://www.recursion.com/">Recursion</a> where I worked on GFlowNets for generative chemistry. I am interested in the general area of reinforcement learning and I am specifically interested in building efficient algorithms which are geared towards sample efficiency in the continual RL scenarios.
              </p>

              <p>
                Besides research, I enjoy photography, reading books and cooking.

              </p>
<!--              <button onclick="research()">Research Interest</button>-->

<!--              <p>-->
<!--                As a cool and fun side project, I started jotting down my understanding of the research papers I read and also some cool concepts in math/ML I find interesting. I am planning to publish at least one research paper notes on a weekly basis.  <a href="https://github.com/SharathRaparthy/research-readings">You can checkout my project here.</a>-->
<!--              </p>-->
              <p style="text-align:center">
                <a target="_blank" href="sharathraparthy@gmail.com"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/SharathRaparthy">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.ca/citations?user=S1R0_UMAAAAJ&hl=en">Google Scholar</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/sharath.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/sharath.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <!-- <h2>Background</h2> -->
        <p>
        <!-- with <a href="https://webdocs.cs.ualberta.ca/~dale/">Dale Schuurmans</a> and <a href="https://www.afaust.info/">Aleksandra Faust</a> in similar areas. -->
        <!-- I was fortunate to also work on consumer privacy rights and legislation with folks from <a href="https://www.law.georgetown.edu/privacy-technology-center">Georgetown's Center on Privacy and Technology.</a></p> -->
              </p>
              <p>
              </p>
        <h2>News</h2>

            <ul>
                    <li> <b> Apr 2022:</b> Joining <a href="https://www.recursion.com/">Recursion</a> as a research intern</li>
                    <li> <b> Oct 2021:</b> Co-organizing <a href="https://paperswithcode.com/rc2021">Machine Learning Reproducibility Challenge</a></li>
                    <li> <b> Oct 2021:</b> Our work on <a href="https://arxiv.org/abs/2110.09419">compositional attention</a> got accepted at ICLR 2022 as a <b style='color:blue !important;'>spotlight presentation</b>.   </li>
                    <li> <b> Oct 2021:</b> New preprint out: <a href="https://arxiv.org/abs/2110.09419">Continual Learning In Environments With Polynomial Mixing Times</a>   </li>
<!--                    <li> <b> Nov 2021:</b> Received Thesis Excellence (DIRO: Excellence-Rédaction) Scholarship to pursue my research.</li>-->
<!--                    <li> <b> Feb 2021:</b> Started a <a href="https://github.com/SharathRaparthy/research-readings">fun side project</a> </li>-->
                    <li> <b> Sep 2020:</b> Started my masters at <a href="https://mila.quebec/">Mila</a> </li>
<!--                    <li> <b> July 2020:</b> Our work CuNAS has been accepted to <a href="https://sim2real.github.io/">RSS, Sim2Real workshop</a></li>-->
<!--                    <li> <b> Feb 2020:</b> Our two works, <a href="https://arxiv.org/abs/2002.07911">SS-ADR</a> and <a href="https://arxiv.org/abs/2002.07956"> Meta-ADR</a> have been accepted to <a href="http://www.betr-rl.ml/2020/">ICLR BeTR-RL workshop</a></li>-->
<!--                    <li> <b> Feb 2020:</b> Excited to announce two preprints: <a href="https://arxiv.org/abs/2002.07911">SS-ADR</a> and <a href="https://arxiv.org/abs/2002.07956"> Meta-ADR</a></li>-->
<!--                  <li> <b> Jan 2020:</b> Started working with <a href="https://sites.google.com/site/irinarish/">Prof. Irina Rish</a> on Meta-Reinforcement Learning </li>-->
<!--                   <li> <b> July 2019:</b> Attended and volunteered the multi-disciplinary conference on <a href="http://rldm.org/">Reinforcement Learning and Decision Making, RLDM-2019</a> </li>-->
<!--                   <li><b> July 2019:</b> Started my internship at <a href="https://mila.quebec/">Montreal Institute for Learning Algorithms (Mila)</a> under <a href="http://liampaull.ca/">Prof. Liam Paull</a> </li>-->
<!--                   <li><b> December 2018:</b> Our paper titled “Explicit Sequence Proximity Models for Hidden State Identification” is accepted to <a href="https://sites.google.com/site/rlponips2018/home/call-for-papers?authuser=0">-->
<!--                  NeurIPS 2018 workshop on Reinforcement Learning under Partial Observability </a>  </li>-->
<!--                   <li><b> October 2018:</b> I am happy to announce that I have been accepted for PyTorch Scholarship Challenge from Facebook. </li>-->
                  </ul>
            <!--<h2>Research 	&#129302;</h2>-->
        <h2>Research</h2>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                <!--
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/todo.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="todo_link">
                <papertitle>TODO_paper_title</papertitle>
              </a>
              <br>
              <strong>Rose E. Wang</strong>,
              TODO,
              <a href="https://cocolab.stanford.edu/ndg">Noah Goodman</a>
              <br>
              <em>TODO conference venue</em>.
              <br>
              <p>TODO tldr</p>
            </td>
          </tr>
                -->
          <tr onmouseout="comp_attention_stop()" onmouseover="comp_attention_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/comp-atten.png" alt="kts" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.09419v1">
                <papertitle>Compositional Attention: Disentangling Search and Retrieval</papertitle>
              </a>
              <br>
              Sarthak Mittal
              <strong>Sharath Chandra Raparthy</strong>, Irina Rish, Yoshua Bengio and Guillaume Lajoie
              <br>
              <br>
              <em>International Conference for Learning Representations (ICLR) 2022</em>.
              <br>
              <b style="color:red">Spotlight Presentation</b>
              <br>
              <br>
              [
              <a href="https://arxiv.org/abs/2110.09419v1">Paper</a>
               /
              <a href="https://github.com/sarthmit/Compositional-Attention">Code</a>
               ]
              <br>
              <p>
              We view the standard Multi-Head attention mechanism from the "Search-Retrieval"  perspective and highlight the rigid associations of keys and values. We propose a new drop-in replacement mechanism, Compositional Attention, where the redundancies highlighted are addressed by disentangling the Searches and Retrievals and composing them dynamically in a context dependent way.
</p>
            </td>
          </tr>

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/figure-1-draft-11.png" alt="hpp" style="border-style: none" width="200">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2112.07066">
                  <papertitle>Continual Learning In Environments With Polynomial Mixing Times</papertitle>
              </a>
              <br>
              Matthew Riemer*, <strong>Sharath Chandra Raparthy*</strong>, Ignacio Cases, Gopeshh Subbaraj, Maximilian Puelma Touzel and Irina Rish
              <br>
              <em>In submission</em>
              [
              <a href="https://arxiv.org/abs/2112.07066">Paper</a> /
              <a href="https://github.com/sharathraparthy/polynomial-mixing-times">Code</a>]
              <br>
              <p>In this work, we concentrate on the major contributor to poor scaling, "Mixing time" of a markov chain induced by a policy.  Mixing times, when ignored, can create myopic biases in the optimization and hence is an impediment to the success in the continual RL problems of greatest interest. We categorize the continual RL problems as Scalable MDPs and formally demonstrate that these exhibit polynomial mixing times. We comment on how exisiting RL algorithms face difficulties in this regime and propose three algorithms which clearly demonstrate sample efficiency.   </p>
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table>
  Template from <a href="https://jonbarron.info/">this website</a>.
</body>

</html>